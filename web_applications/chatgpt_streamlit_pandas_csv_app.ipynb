{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT Pandas CSV Streamlit App\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1IgRwKCl2oLXnW5UuLroSVPP0db8Ajahe?usp=sharing)\n",
        "\n",
        "## Overview\n",
        "| Detail Tag            | Information                                                                                        |\n",
        "|-----------------------|----------------------------------------------------------------------------------------------------|\n",
        "| Originally Created By | Ariel Herrera arielherrera@analyticsariel.com |\n",
        "| External References   | Open AI API |\n",
        "| Input Datasets        | Source name |\n",
        "| Output Datasets       | Source name |\n",
        "| Input Data Source     | Pandas DataFrame |\n",
        "| Output Data Source    | String |\n",
        "\n",
        "## History\n",
        "| Date         | Developed By  | Reason                                                |\n",
        "|--------------|---------------|-------------------------------------------------------|\n",
        "| 1st May 2023 | Ariel Herrera | Create notebook. |\n",
        "\n",
        "## Getting Started\n",
        "1. Copy this notebook -> File -> Save a Copy in Drive\n",
        "2. Directions\n",
        "\n",
        "## Useful Resources\n",
        "- [Google Colab Cheat Sheet](https://towardsdatascience.com/cheat-sheet-for-google-colab-63853778c093)"
      ],
      "metadata": {
        "id": "p8_8vOvimyv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"blue\">Install Packages</font>"
      ],
      "metadata": {
        "id": "dhjG-Ab6m88P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvlYkCQ9vFiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8763ab8b-d1a3-40bd-abe2-29336c983992"
      },
      "source": [
        "!pip install -q streamlit langchain openai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m696.4/696.4 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waCfwniZOow8"
      },
      "source": [
        "## <font color=\"blue\">Streamlit App</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import sqlite3\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.pool import StaticPool\n",
        "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain\n",
        "\n",
        "\n",
        "#####################################\n",
        "#            FUNCTIONS              #\n",
        "#####################################\n",
        "@st.cache_data()\n",
        "def load_data(url):\n",
        "    \"\"\"\n",
        "    load data from url\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(url)\n",
        "    return df\n",
        "\n",
        "def prepare_data(df):\n",
        "    \"\"\"\n",
        "    lowercase columns\n",
        "    \"\"\"\n",
        "    df.columns = [x.replace(' ', '_').lower() for x in df.columns]\n",
        "    return df\n",
        "\n",
        "\n",
        "#####################################\n",
        "#        LOCALS & CONSTANTS         #\n",
        "#####################################\n",
        "table_name = 'statesdb'\n",
        "uri = \"file::memory:?cache=shared\"\n",
        "\n",
        "\n",
        "#####################################\n",
        "#            HOME PAGE              #\n",
        "#####################################\n",
        "st.title('ChatGPT Pandas CSV Streamlit :house:')\n",
        "st.subheader('Upload a file to query')\n",
        "\n",
        "# read file\n",
        "uploaded_file = st.file_uploader(\"Choose a csv file\")\n",
        "if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    st.write(df)\n",
        "\n",
        "    # api key\n",
        "    openai_api_key = st.text_input(\n",
        "        \"API key\", \n",
        "        placeholder='1234567890',\n",
        "        type='password',\n",
        "        disabled=False,\n",
        "        help='Enter your OpenAI api key.'\n",
        "    )\n",
        "\n",
        "    # user query\n",
        "    user_q = st.text_input(\n",
        "        \"User Query\", \n",
        "        help=\"Enter a question based on the dataset\")\n",
        "\n",
        "    # commit data to sql\n",
        "    data = prepare_data(df)\n",
        "    conn = sqlite3.connect(uri)\n",
        "    data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "\n",
        "    # create db engine\n",
        "    eng = create_engine(\n",
        "        url='sqlite:///file:memdb1?mode=memory&cache=shared', \n",
        "        poolclass=StaticPool, # single connection for requests\n",
        "        creator=lambda: conn)\n",
        "    db = SQLDatabase(engine=eng)\n",
        "\n",
        "    # create open AI conn and db chain\n",
        "    if openai_api_key:\n",
        "      llm = OpenAI(\n",
        "          openai_api_key=openai_api_key, \n",
        "          temperature=0, # creative scale\n",
        "          max_tokens=300)\n",
        "      db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\n",
        "\n",
        "    # run query and display result\n",
        "    if openai_api_key and user_q:\n",
        "        result = db_chain.run(user_q)\n",
        "        st.write(result)"
      ],
      "metadata": {
        "id": "meJ36PefNftd",
        "outputId": "853f89cd-a7a4-4e1f-ca46-66cc91875a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run streamlit in background"
      ],
      "metadata": {
        "id": "kccYE2lkN20y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "Zv912rRAN0fs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expose the port 8501\n",
        "Then just click in the `url` showed.\n",
        "\n",
        "A `log.txt`file will be created."
      ],
      "metadata": {
        "id": "h_KW9juhOCuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "XTGAizLhOIgC",
        "outputId": "994e2307-9997-4a92-f660-7d73eb29a5d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.11s\n",
            "your url is: https://tough-bags-kiss-34-125-70-219.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End Notebook"
      ],
      "metadata": {
        "id": "l2FVELl_nKmV"
      }
    }
  ]
}
